// Generate ISP support requests for feature enablement
// Helps customers get technical justification for enabling restricted features

use anyhow::Result;
use serde::{Deserialize, Serialize};

#[derive(Debug, Serialize, Deserialize)]
pub struct IspSupportRequest {
    pub feature: RequestedFeature,
    pub justification: String,
    pub technical_requirements: Vec<String>,
    pub benefits: Vec<String>,
    pub impact: String,
    pub urgency: Urgency,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub enum RequestedFeature {
    GpuPassthrough,
    IommuEnable,
    NestedVirtualization,
    CpuFeatureExposure,
    SriovEnable,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub enum Urgency {
    Critical,
    High,
    Medium,
    Low,
}

pub fn generate_gpu_passthrough_request(
    gpu_pci_id: Option<String>,
    use_case: &str,
) -> Result<String> {
    let request = format!(
        r#"Subject: GPU Passthrough Configuration Request - Technical Justification

Dear [ISP Support Team],

I am requesting GPU passthrough configuration for my instance. Below is the technical
justification and requirements.

═══════════════════════════════════════════════════════════════
FEATURE REQUEST: GPU Passthrough (PCI Device Assignment)
═══════════════════════════════════════════════════════════════

TECHNICAL REQUIREMENTS:
─────────────────────────────────────────────────────────────
1. Enable IOMMU on hypervisor host
   - Intel: Add 'intel_iommu=on iommu=pt' to host kernel parameters
   - AMD: Add 'amd_iommu=on iommu=pt' to host kernel parameters

2. Bind GPU to vfio-pci driver on host
   - Identify GPU PCI ID: {}
   - Load vfio-pci module: modprobe vfio-pci
   - Bind GPU: echo "[GPU_PCI_ID]" > /sys/bus/pci/drivers/vfio-pci/new_id

3. Assign PCI device to my VM
   - Proxmox: Add to VM config: hostpci0: [GPU_PCI_ID],pcie=1
   - QEMU: Add -device vfio-pci,host=[GPU_PCI_ID]
   - Ensure BIOS has VT-d/IOMMU enabled

USE CASE:
─────────────────────────────────────────────────────────────
{}

BUSINESS JUSTIFICATION:
─────────────────────────────────────────────────────────────
- Machine Learning: Training models requires GPU acceleration (100x faster than CPU)
- Video Rendering: Real-time encoding/transcoding requires dedicated GPU
- CAD/Simulation: Engineering workloads need GPU compute
- Cost Optimization: GPU cloud instances are $3-5/hour, dedicated GPU on my instance
  saves significant monthly costs

TECHNICAL BENEFITS:
─────────────────────────────────────────────────────────────
✓ No performance overhead (native GPU access)
✓ Isolated from other tenants (dedicated PCI device)
✓ Better utilization of your hardware (GPU not sitting idle)
✓ Reduces need for expensive GPU cloud instances

IMPACT ON HOST:
─────────────────────────────────────────────────────────────
- Minimal: Only affects my VM, no impact on other tenants
- IOMMU provides hardware-level isolation
- GPU can be reassigned to another VM if I terminate service
- Standard configuration supported by Proxmox/QEMU/KVM

URGENCY: HIGH
─────────────────────────────────────────────────────────────
Current workaround (CPU-only processing) is 100x slower and blocks production workloads.

COMPARABLE SERVICES:
─────────────────────────────────────────────────────────────
Other providers offering GPU passthrough on dedicated servers:
- Hetzner: Full GPU passthrough on dedicated servers
- Vultr: Bare metal with GPU support
- OVH: GPU passthrough available on select SKUs
- Scaleway: GPU instances with passthrough

If this configuration is not feasible, please advise if:
1. You offer GPU-enabled instances (pricing?)
2. I can upgrade to dedicated server with full hardware access
3. Alternative solutions are available

Thank you for your consideration. Please let me know if you need any additional
technical details or clarification.

═══════════════════════════════════════════════════════════════
Generated by op-dbus system introspection tool
Technical contact: [Your Email]
Instance ID: [Your Instance ID]
═══════════════════════════════════════════════════════════════
"#,
        gpu_pci_id.unwrap_or_else(|| "0000:01:00.0 (detected by lspci)".to_string()),
        use_case
    );

    Ok(request)
}

pub fn generate_nested_virt_request(use_case: &str) -> Result<String> {
    let request = format!(
        r#"Subject: Nested Virtualization Enable Request

Dear [ISP Support Team],

I am requesting nested virtualization be enabled for my instance.

═══════════════════════════════════════════════════════════════
FEATURE REQUEST: Nested Virtualization (KVM-in-KVM)
═══════════════════════════════════════════════════════════════

TECHNICAL REQUIREMENTS:
─────────────────────────────────────────────────────────────
1. Enable nested virtualization on hypervisor host
   - Intel: echo "Y" > /sys/module/kvm_intel/parameters/nested
   - AMD: echo "Y" > /sys/module/kvm_amd/parameters/nested

2. Expose VMX/SVM CPU flag to my VM
   - Ensure host CPU features are passed through
   - VM must see 'vmx' (Intel) or 'svm' (AMD) in /proc/cpuinfo

3. Enable nested EPT/NPT (optional, for performance)
   - Intel: ept=1,vpid=1
   - AMD: npt=1

USE CASE:
─────────────────────────────────────────────────────────────
{}

BUSINESS JUSTIFICATION:
─────────────────────────────────────────────────────────────
- Development/Testing: Need to test Kubernetes, Docker, Proxmox inside VM
- CI/CD: Build pipelines require nested containerization
- Multi-tenant SaaS: Provide isolated VMs to customers
- Education: Training environment for virtualization technologies

TECHNICAL BENEFITS:
─────────────────────────────────────────────────────────────
✓ No additional hardware cost
✓ Isolated from other tenants (standard VM isolation still applies)
✓ Performance acceptable for dev/test workloads (80-90% native)
✓ Industry standard (AWS, GCP, Azure all support nested virt)

IMPACT ON HOST:
─────────────────────────────────────────────────────────────
- Minimal: Single kernel parameter change
- No performance impact on other VMs
- Security boundary maintained (nested VM cannot escape to host)
- Can be disabled per-VM if needed

URGENCY: MEDIUM
─────────────────────────────────────────────────────────────
Blocks development of containerized applications and testing workflows.

COMPARABLE SERVICES:
─────────────────────────────────────────────────────────────
- AWS: Supports nested virtualization on metal instances
- GCP: Nested virtualization enabled by default
- Azure: Supports nested virt on Dv3/Ev3 instances
- DigitalOcean: Nested virt available

Please advise if this can be enabled, or if I need to upgrade to a different
instance type/plan.

═══════════════════════════════════════════════════════════════
Generated by op-dbus
═══════════════════════════════════════════════════════════════
"#,
        use_case
    );

    Ok(request)
}

pub fn generate_iommu_enable_request() -> Result<String> {
    let request = r#"Subject: IOMMU/VT-d Enable Request for PCI Device Isolation

Dear [ISP Support Team],

I am requesting IOMMU (Intel VT-d / AMD-Vi) be enabled on the hypervisor host.

═══════════════════════════════════════════════════════════════
FEATURE REQUEST: IOMMU/VT-d Enable
═══════════════════════════════════════════════════════════════

TECHNICAL REQUIREMENTS:
─────────────────────────────────────────────────────────────
1. Enable VT-d/AMD-Vi in BIOS on hypervisor host
2. Add kernel parameter to host: intel_iommu=on (or amd_iommu=on)
3. Verify with: dmesg | grep -i iommu

BUSINESS JUSTIFICATION:
─────────────────────────────────────────────────────────────
- Required for: GPU passthrough, NVMe passthrough, network card passthrough
- Security: Hardware-level isolation between VMs
- Performance: Direct device access without virtualization overhead
- Compliance: Some industries require IOMMU for security certification

TECHNICAL BENEFITS:
─────────────────────────────────────────────────────────────
✓ Enable PCI device passthrough (GPU, NVMe, network)
✓ Hardware-level DMA protection (prevents DMA attacks)
✓ Better multi-tenant isolation
✓ Required for modern virtualization best practices

IMPACT ON HOST:
─────────────────────────────────────────────────────────────
- Minimal: Boot parameter change + reboot
- Slight performance overhead (~2-3%) but improved security
- Industry standard for enterprise hypervisors
- Required for proper VT-d/AMD-Vi functionality

This is a prerequisite for GPU passthrough and other advanced features.

═══════════════════════════════════════════════════════════════
Generated by op-dbus
═══════════════════════════════════════════════════════════════
"#;

    Ok(request.to_string())
}
